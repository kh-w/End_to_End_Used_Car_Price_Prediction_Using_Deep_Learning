{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7da909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.project import get_project_settings\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "now = str(datetime.datetime.now().year)+str('0'+str(datetime.datetime.now().month))[-2:]+str('0'+str(datetime.datetime.now().day))[-2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify the scope of the dataset by data-listing-id (cars)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "make_all = ['Toyota','Subaru','Mitsubishi','Honda','Nissan','Mazda'] # mainstream mass-market Japanese brands\n",
    "priceMx = 20000 # dollars\n",
    "distance = 500 # miles\n",
    "zipcode = 60126 # my zipcode \n",
    "cars_per_page = 100\n",
    "\n",
    "for j in range(0,6):\n",
    "\n",
    "    make = make_all[j]\n",
    "\n",
    "    url = 'https://www.cars.com/shopping/results/?stock_type=used&makes%5B%5D='+make.lower()+'&models%5B%5D=&maximum_distance='+str(distance)+'&zip='+str(zipcode)+'&list_price_max='+str(priceMx)+'&page_size='+str(cars_per_page)\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    print(make)\n",
    "\n",
    "    cars_total = soup.find('span', class_ = 'total-entries').text\n",
    "    cars_total = int(cars_total.replace(',' , '').replace(' matches' , ''))\n",
    "\n",
    "    print(cars_total)\n",
    "\n",
    "    no_of_pages = int(cars_total/cars_per_page) + (cars_total%cars_per_page>0)\n",
    "\n",
    "    if not os.path.exists('car lists'):\n",
    "        os.makedirs('car lists')\n",
    "\n",
    "    for i in range(0,no_of_pages):\n",
    "\n",
    "        print(str(j+1)+' '+make+' '+str(i+1)+'/'+str(no_of_pages))\n",
    "\n",
    "        sleep(np.random.choice([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])+5)\n",
    "\n",
    "        url = 'https://www.cars.com/shopping/results/?stock_type=used&makes%5B%5D='+make.lower()+'&models%5B%5D=&maximum_distance='+str(distance)+'&zip='+str(zipcode)+'&list_price_max='+str(priceMx)+'&page_size='+str(cars_per_page)+'&page='+str(i+1)\n",
    "        print(url)\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "        try:\n",
    "            #data = json.loads(soup.find('script',{'id':'vehicleItemListSchema'}).contents[0][9:-5])\n",
    "            data = [div[\"data-listing-id\"] for div in soup.find_all(\"div\", class_=\"vehicle-card\")]\n",
    "        except:\n",
    "            data = 'Unable to get data'\n",
    "\n",
    "        file = open(\"car lists/\"+make+now+\"carlist\"+str(i)+\".txt\",\"w\")\n",
    "        file.write(str(data).replace(\"'\",'\"'))\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Links to all cars\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(\"car lists\", \"**\", \"*.txt\"), recursive=True)\n",
    "\n",
    "linkvector = []\n",
    "\n",
    "for file_path in list_of_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            link = f\"https://www.cars.com/vehicledetail/{item}/\"\n",
    "            linkvector.append(link)\n",
    "\n",
    "unique_links = list(set(linkvector))\n",
    "\n",
    "print(len(unique_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84963fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Grab info from each car\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "now = str(datetime.datetime.now().year)+str('0'+str(datetime.datetime.now().month))[-2:]+str('0'+str(datetime.datetime.now().day))[-2:]\n",
    "\n",
    "url = unique_links\n",
    "\n",
    "if not os.path.exists('datasets'):\n",
    "        os.makedirs('datasets')\n",
    "\n",
    "data_folder = Path(\"datasets/\")\n",
    "\n",
    "column_names = [\n",
    "    \"make\", \"year\", \"trim\", \"model\", \"stock_type\", \"fuel_type\", \"bodystyle\", \"photo_count\",\n",
    "    \"exterior_color\", \"interior_color\", \"drivetrain\", \"fuel_type\", \"transmission\", \"engine\",\n",
    "    \"mileage\", \"accidents_or_damage\", \"clean_title\", \"one_owner_vehicle\", \"personal_use_only\",\n",
    "    \"open_recall\", \"comfort_rating\", \"interior_rating\", \"performance_rating\", \"value_rating\",\n",
    "    \"exterior_rating\", \"reliability_rating\", \"singleurl\", \"price\"\n",
    "]\n",
    "\n",
    "dataset = pd.DataFrame([], columns=column_names)\n",
    "\n",
    "def try_get_text(soup, label):\n",
    "    try:\n",
    "        return soup.find('dt', string=label).find_next_sibling('dd').get_text(strip=True)\n",
    "    except:\n",
    "        return \"NA\"\n",
    "\n",
    "def try_get_rating(soup, label):\n",
    "    try:\n",
    "        return soup.find('span', class_='sds-definition-list__display-name', string=label).parent.find('span', class_='sds-definition-list__value').get_text(strip=True)\n",
    "    except:\n",
    "        return \"NA\"\n",
    "\n",
    "def try_get_json_value(soup, label):\n",
    "    try:\n",
    "        return json.loads(soup.find(\"script\", {\"type\": \"application/json\", \"id\": \"initial-als-data\"}).string).get(label)\n",
    "    except:\n",
    "        return \"NA\"\n",
    "\n",
    "def try_get_photo_count(soup, label):\n",
    "    label = 'photo_count'\n",
    "    try:\n",
    "        return json.loads(soup.find(\"script\", {\"type\": \"application/json\", \"id\": \"initial-activity-data\"}).string).get(label)\n",
    "    except:\n",
    "        return \"NA\"\n",
    "    \n",
    "for i in range(10080,len(url)): # range(0, len(url))\n",
    "\n",
    "    singleurl = url[i][:-1]\n",
    "\n",
    "    time.sleep(np.random.uniform(4, 10))\n",
    "\n",
    "    response = requests.get(singleurl, headers=headers, timeout=100)\n",
    "    soup = BeautifulSoup(response.content, 'html')\n",
    "\n",
    "    print(str(i)+' of '+str(len(url)))\n",
    "    print(singleurl)\n",
    "\n",
    "    exterior_color = try_get_text(soup, 'Exterior color')\n",
    "    interior_color = try_get_text(soup, 'Interior color')\n",
    "    drivetrain = try_get_text(soup, 'Drivetrain')\n",
    "    fuel_type = try_get_text(soup, 'Fuel type')\n",
    "    transmission = try_get_text(soup, 'Transmission')\n",
    "    engine = try_get_text(soup, 'Engine')\n",
    "    mileage = try_get_text(soup, 'Mileage')\n",
    "    accidents_or_damage = try_get_text(soup, 'Accidents or damage')\n",
    "    clean_title = try_get_text(soup, 'Clean title')\n",
    "    one_owner_vehicle = try_get_text(soup, '1-owner vehicle')\n",
    "    personal_use_only = try_get_text(soup, 'Personal use only')\n",
    "    open_recall = try_get_text(soup, 'Open recall')\n",
    "\n",
    "    comfort_rating = try_get_rating(soup, 'Comfort')\n",
    "    interior_rating = try_get_rating(soup, 'Interior')\n",
    "    performance_rating = try_get_rating(soup, 'Performance')\n",
    "    value_rating = try_get_rating(soup, 'Value')\n",
    "    exterior_rating = try_get_rating(soup, 'Exterior')\n",
    "    reliability_rating = try_get_rating(soup, 'Reliability')\n",
    "    \n",
    "    listing_id = try_get_json_value(soup, \"listing_id\")\n",
    "    year = try_get_json_value(soup, \"model_year\")\n",
    "    photo_count = try_get_photo_count(soup, \"photo_count\")\n",
    "    trim = try_get_json_value(soup, \"trim\")\n",
    "    model = try_get_json_value(soup, \"model\")\n",
    "    stock_type = try_get_json_value(soup, \"stock_type\")\n",
    "    bodystyle = try_get_json_value(soup, \"bodystyle\")\n",
    "    make = try_get_json_value(soup, \"make\")\n",
    "    price = try_get_json_value(soup, \"price\")\n",
    "\n",
    "    data_point = [make,\n",
    "                  year,\n",
    "                  trim,\n",
    "                  model,\n",
    "                  stock_type,\n",
    "                  fuel_type,\n",
    "                  bodystyle,\n",
    "                  photo_count,\n",
    "                  exterior_color,\n",
    "                  interior_color,\n",
    "                  drivetrain,\n",
    "                  fuel_type,\n",
    "                  transmission,\n",
    "                  engine,\n",
    "                  mileage,\n",
    "                  accidents_or_damage,\n",
    "                  clean_title,\n",
    "                  one_owner_vehicle,\n",
    "                  personal_use_only,\n",
    "                  open_recall,\n",
    "                  comfort_rating,\n",
    "                  interior_rating,\n",
    "                  performance_rating,\n",
    "                  value_rating,\n",
    "                  exterior_rating,\n",
    "                  reliability_rating,\n",
    "                  singleurl,\n",
    "                  price]\n",
    "\n",
    "    dataset.loc[len(dataset)] = data_point\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"datasets/\"+now+'_dataset_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
